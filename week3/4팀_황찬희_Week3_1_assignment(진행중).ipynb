{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ugGR7pnI4WSe"
      },
      "source": [
        "# Week3_1 Assignment\n",
        "\n",
        "## [BASIC](#Basic) \n",
        "- 토크나이징이 완료된 위키 백과 코퍼스를 다운받고 **단어 사전을 구축하는 함수를 구현**할 수 있다.\n",
        "- `Skip-Gram` 방식의 학습 데이터 셋을 생성하는 **Dataset과 Dataloader 클래스를 구현**할 수 있다.\n",
        "- **Negative Sampling** 함수를 구현할 수 있다. \n",
        "\n",
        "\n",
        "## [CHALLENGE](#Challenge)\n",
        "- Skip-Gram을 학습 과정 튜토리얼을 따라하며, **Skip-Gram을 학습하는 클래스를 구현**할 수 있다. \n",
        "\n",
        "\n",
        "## [ADVANCED](#Advanced)\n",
        "- Skip-Gram 방식으로 word embedding을 학습하는 **Word2Vec 클래스를 구현**하고 실제로 학습할 수 있다.\n",
        "- 학습이 완료된 word embedding을 불러와 **Gensim 패키지를 사용해 유사한 단어**를 뽑을 수 있다. \n",
        "\n",
        "### Reference\n",
        "- [Skip-Gram negative sampling 한국어 튜토리얼](https://wikidocs.net/69141)\n",
        "    - (참고) 위 튜토리얼에서는 target word와 context word 페어의 레이블은 1로, target word와 negative sample word 페어의 레이블은 0이 되도록 학습 데이터를 구현해 binary classification을 구현한다. 하지만 우리는 word2vec 논문 방식을 그대로 따르기 위해 label을 생성하지 않고 대신 loss 함수를 변행해서 binary classification을 학습할 것이다. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-19T14:29:36.641276Z",
          "start_time": "2022-02-19T14:29:36.638642Z"
        },
        "id": "HlEy3xfY4WSh"
      },
      "outputs": [],
      "source": [
        "import os \n",
        "import sys\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from typing import List, Dict\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-19T12:50:41.644583Z",
          "start_time": "2022-02-19T12:50:41.642937Z"
        },
        "id": "cBrr7-gt4jnf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "539fe9b1-065b-4932-872b-5a756ba889bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.17.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.4.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.5)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.63.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.47)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-19T14:26:59.276355Z",
          "start_time": "2022-02-19T14:26:58.411434Z"
        },
        "id": "6mC9lhsJ4WSh"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.autograd import Variable\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import SGD\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-19T14:30:05.586472Z",
          "start_time": "2022-02-19T14:30:05.583611Z"
        },
        "id": "17g7UZ5g4WSi"
      },
      "outputs": [],
      "source": [
        "# seed\n",
        "seed = 7777\n",
        "np.random.seed(seed)\n",
        "random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed_all(seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-19T14:30:06.721039Z",
          "start_time": "2022-02-19T14:30:06.717559Z"
        },
        "id": "v3UlC7Jn4WSi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7d17098-c02a-4f0d-c831-cd9a2de8368f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# available GPUs : 1\n",
            "GPU name : Tesla P100-PCIE-16GB\n",
            "cuda\n"
          ]
        }
      ],
      "source": [
        "# device type\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(f\"# available GPUs : {torch.cuda.device_count()}\")\n",
        "    print(f\"GPU name : {torch.cuda.get_device_name()}\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k8sfv5KY4WSk"
      },
      "source": [
        "## Basic"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sHs8_LU04WSj"
      },
      "source": [
        "### 토크나이징이 완료된 위키 백과 코퍼스 다운로드 및 불용어 사전 크롤링\n",
        "- 나의 구글 드라이브에 데이터를 다운받아 영구적으로 사용할 수 있도록 하자. \n",
        "    - [데이터 다운로드 출처](https://ratsgo.github.io/embedding/downloaddata.html)\n",
        "- 다운받은 데이터는 토크나이징이 완료된 상태이지만 불용어를 포함하고 있다. 따라서 향후 불용어를 제거하기 위해 불용어 사전을 크롤링하자. \n",
        "    - [불용어 사전 출처](https://www.ranks.nl/stopwords/korean)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "KYiz1fdNsAqp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3bbfd843-6753-41ed-d6a5-60d19aeccc1b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "Z2WZ0P4wsAqp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "085b35ec-2de4-4995-a38e-f46e628b8251"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: '/content/drive/MyDrive # 데이터 다운로드할 위치 입력'\n",
            "/content\n"
          ]
        }
      ],
      "source": [
        "%cd '/content/drive/MyDrive' # 데이터 다운로드할 위치 입력"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-19T14:27:11.886643Z",
          "start_time": "2022-02-19T14:27:11.884858Z"
        },
        "id": "4QPBJ6UZ4WSj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c3283a3-74d9-411e-cc70-b415d96d159b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.7/dist-packages (4.2.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from gdown) (4.63.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.7/dist-packages (from gdown) (2.23.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from gdown) (1.15.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from gdown) (4.6.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from gdown) (3.6.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (3.0.4)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Access denied with the following error:\n",
            "\n",
            " \tCannot retrieve the public link of the file. You may need to change\n",
            "\tthe permission to 'Anyone with the link', or have had many accesses. \n",
            "\n",
            "You may still be able to access the file from the browser:\n",
            "\n",
            "\t https://drive.google.com/u/0/uc?id=1Ybp_DmzNEpsBrUKZ1-NoPDzCMO39f-fx \n",
            "\n",
            "replace tokenized/korquad_mecab.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace tokenized/wiki_ko_mecab.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace tokenized/corpus_mecab_jamo.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: N\n"
          ]
        }
      ],
      "source": [
        "# 데이터 다운로드\n",
        "!pip install gdown\n",
        "!gdown https://drive.google.com/u/0/uc?id=1Ybp_DmzNEpsBrUKZ1-NoPDzCMO39f-fx\n",
        "!unzip -qq '/content/drive/MyDrive/tokenized.zip'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-19T14:27:15.633947Z",
          "start_time": "2022-02-19T14:27:13.829982Z"
        },
        "id": "cTHCHmO24WSj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90dd45a5-1d96-4d21-b41d-2b2e1a4e3a3a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
            "  InsecureRequestWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# Korean stop words: 677\n"
          ]
        }
      ],
      "source": [
        "# 한국어 불용어 리스트 크롤링\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "url = \"https://www.ranks.nl/stopwords/korean\"\n",
        "response = requests.get(url, verify = False)\n",
        "\n",
        "if response.status_code == 200:\n",
        "    soup = BeautifulSoup(response.text,'html.parser')\n",
        "    content = soup.select_one('#article178ebefbfb1b165454ec9f168f545239 > div.panel-body > table > tbody > tr')\n",
        "    stop_words=[]\n",
        "    for x in content.strings:\n",
        "        x=x.strip()\n",
        "        if x:\n",
        "            stop_words.append(x)\n",
        "    print(f\"# Korean stop words: {len(stop_words)}\")\n",
        "else:\n",
        "    print(response.status_code)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-19T14:27:15.642775Z",
          "start_time": "2022-02-19T14:27:15.635333Z"
        },
        "id": "3d0IqhDF4WSk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "a525512e-aa01-4469-8c83-41bf55fbf0c0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'아'"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "stop_words[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_t76Q1pQ4WSk"
      },
      "source": [
        "### 단어 사전 구축 함수 구현 \n",
        "- 문서 리스트를 입력 받아 사전을 생성하는 `make_vocab()` 함수를 구현하라.\n",
        "- 함수 정의\n",
        "    - 입력 매개변수\n",
        "        - docs : 문서 리스트\n",
        "        - min_count : 최소 단어 등장 빈도수 (단어 빈도가 `min_count` 미만인 단어는 사전에 포함하지 않음)\n",
        "    - 조건\n",
        "        - 문서 길이 제한\n",
        "            - 단어 개수가 3개 이하인 문서는 처리하지 않음. (skip)\n",
        "        - 사전에 포함되는 단어 빈도수 제한\n",
        "            - 단어가 빈도가 `min_count` 미만은 단어는 사전에 포함하지 않음.\n",
        "        - 불용어 제거 \n",
        "            - 불용어 리스트에 포함된 단어는 제거 \n",
        "    - 반환값 \n",
        "        - word2count : 단어별 빈도 사전 (key: 단어, value: 등장 횟수)\n",
        "        - wid2word : 단어별 인덱스(wid) 사전 (key: 단어 인덱스(int), value: 단어)\n",
        "        - word2wid : 인덱스(wid)별 단어 사전 (key: 단어, value: 단어 인덱스(int))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-19T14:33:01.637431Z",
          "start_time": "2022-02-19T14:32:56.730711Z"
        },
        "id": "xkjqztIA4WSl"
      },
      "outputs": [],
      "source": [
        "# 코퍼스 로드\n",
        "\n",
        "docs = '/content/tokenized/ratings_hannanum.txt'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-19T14:33:03.423002Z",
          "start_time": "2022-02-19T14:33:03.419818Z"
        },
        "id": "WAKB6bbt4WSl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4b9545b-bec0-4fd1-b22f-10cb660d6f33"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# wiki documents: 39\n"
          ]
        }
      ],
      "source": [
        "print(f\"# wiki documents: {len(docs):,}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f = open(docs, \"r\")\n",
        "# while True:\n",
        "#   line = f.readline()\n",
        "#   if not line:        # 더 이상 읽을게 없다면\n",
        "#         break        \n",
        "#   print(line)\n"
      ],
      "metadata": {
        "id": "B8oEuM60DQi6"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f.readline())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VR-X7R_9Sd79",
        "outputId": "5684e3cf-911a-434a-997c-6a6a1f610144"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "어리 ㄹ 때 보 고 지금 다시봐 도 재밌어욬ㅋ\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-19T14:33:04.016885Z",
          "start_time": "2022-02-19T14:33:03.962269Z"
        },
        "id": "-OI1MCXv4WSl"
      },
      "outputs": [],
      "source": [
        "# 문서 개수를 500개로 줄임\n",
        "docs=random.sample(f.readlines(),500)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"# wiki documents: {len(docs):,}\")"
      ],
      "metadata": {
        "id": "mP5wGu9YwDUw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d79d7e8d-369e-488d-e9f5-37eec06f6403"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# wiki documents: 500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def test(s): \n",
        "  hangul = re.compile('[^ ㄱ-ㅣ가-힣+]') # 한글과 띄어쓰기를 제외한 모든 글자  \n",
        "  lst=[]\n",
        "  for i in range(len(s)):\n",
        "    result = hangul.sub('', s[i]) # 한글과 띄어쓰기를 제외한 모든 부분을 제거\n",
        "    lst.append(result) \n",
        "  return lst\n",
        "\n"
      ],
      "metadata": {
        "id": "VJQEhBcHkXzG"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-19T14:33:26.392627Z",
          "start_time": "2022-02-19T14:33:26.382358Z"
        },
        "id": "aJaEAVm9sAqv"
      },
      "outputs": [],
      "source": [
        "# 문서 내 숫자, 영어 대소문자, 특수문자를 제거 (re package 사용)\n",
        "\n",
        "docs =test(docs)# None"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Check : {docs[0][:1000]}\")"
      ],
      "metadata": {
        "id": "sytiSICawMk5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f2f4210-3c26-4d03-b2b7-e8cffa7a8ee7"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Check : 캐릭터들 의 개연성  긴장 과 재미  모든컷 이 완벽 하고 자연 스럽 다  굉장 하 다  진짜\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 152,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-19T14:33:27.904880Z",
          "start_time": "2022-02-19T14:33:27.899620Z"
        },
        "id": "OAkkQsvO4WSl"
      },
      "outputs": [],
      "source": [
        "def make_vocab(docs:List[str], min_count:int):\n",
        "    from sklearn.feature_extraction.text import CountVectorizer\n",
        "    \"\"\"\n",
        "    'docs'문서 리스트를 입력 받아 단어 사전을 생성.\n",
        "    \n",
        "    return \n",
        "        - word2count : 단어별 빈도 사전\n",
        "        - wid2word : 단어별 인덱스(wid) 사전 \n",
        "        - word2wid : 인덱스(wid)별 단어 사전\n",
        "    \"\"\"\n",
        "\n",
        "    word2count = dict()\n",
        "    word2id = dict()\n",
        "    id2word = dict()\n",
        "\n",
        "\n",
        "    for doc in tqdm(docs):\n",
        "        word_list = doc.split()\n",
        "        for word in word_list:\n",
        "          if word in word2count:\n",
        "            word2count[word]=word2count[word]+1\n",
        "          else:\n",
        "            word2count[word]=1 \n",
        "    word2count = {key:value for key, value in word2count.items() if value >= min_count }\n",
        "\n",
        "    count_vectorizer = CountVectorizer()\n",
        "    count_vectorizer.fit(docs) \n",
        "    word2id=count_vectorizer.vocabulary_\n",
        "\n",
        "    id2word = {v: k for k, v in word2id.items()}\n",
        "    id2word=sorted(id2word.items(), reverse=False)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        # 1. 문서 길이 제한\n",
        "        # 2. 임시 딕셔너리(_word2count)에 단어별 등장 빈도 기록\n",
        "        # 3. 불용어 제거\n",
        "\n",
        "    # 4. 토큰 최소 빈도를 만족하는 토큰만 사전에 추가\n",
        "    \n",
        "    return word2count, word2id, id2word"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 153,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-19T14:33:30.157872Z",
          "start_time": "2022-02-19T14:33:28.473330Z"
        },
        "id": "ieS5SiQx4WSm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a551aa6-1498-4603-b97d-3d57201ffb74"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 500/500 [00:00<00:00, 82731.15it/s]\n"
          ]
        }
      ],
      "source": [
        "word2count, word2id, id2word = make_vocab(docs, min_count=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 154,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-19T14:33:30.754722Z",
          "start_time": "2022-02-19T14:33:30.752115Z"
        },
        "id": "cT1MRN1EJtx6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fdca8479-57f5-46a3-dc25-403708d60c13"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5,109\n"
          ]
        }
      ],
      "source": [
        "doc_len = sum(word2count.values()) # 문서 내 모든 단어의 개수 (단어별 등장 빈도의 총 합)\n",
        "print(f\"{doc_len:,}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 155,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-19T14:33:32.916830Z",
          "start_time": "2022-02-19T14:33:32.914355Z"
        },
        "id": "e_1MneB54WSm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2e277bf-d763-4bb1-ea1d-1664d173ff09"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# unique word : 2,019\n"
          ]
        }
      ],
      "source": [
        "print(f\"# unique word : {len(word2id):,}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gHxtZqtk4WSm"
      },
      "source": [
        "### Dataset 클래스 구현\n",
        "- Skip-Gram 방식의 학습 데이터 셋(`Tuple(target_word, context_word)`)을 생성하는 `CustomDataset` 클래스를 구현하라.\n",
        "- 클래스 정의\n",
        "    - 생성자(`__init__()` 함수) 입력 매개변수\n",
        "        - docs: 문서 리스트\n",
        "        - word2id: 단어별 인덱스(wid) 사전\n",
        "        - window_size: Skip-Gram의 윈도우 사이즈\n",
        "    - 메소드\n",
        "        - `make_pair()`\n",
        "            - 문서를 단어로 쪼개고, 사전에 존재하는 단어들만 단어 인덱스로 변경\n",
        "            - Skip-gram 방식의 `(target_word, context_word)` 페어(tuple)들을 `pairs` 리스트에 담아 반환\n",
        "        - `__len__()`\n",
        "            - `pairs` 리스트의 개수 반환\n",
        "        - `__getitem__(index)`\n",
        "            - `pairs` 리스트를 인덱싱\n",
        "    - 주의 사항\n",
        "        - `nn.Module`를 부모 클래스로 상속 받음 \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 180,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-19T14:33:38.111290Z",
          "start_time": "2022-02-19T14:33:38.104531Z"
        },
        "id": "UPiLcYCZ4WSm"
      },
      "outputs": [],
      "source": [
        "class CustomDataset(Dataset):\n",
        "    \"\"\"\n",
        "    문서 리스트를 받아 skip-gram 방식의 (target_word, context_word) 데이터 셋을 생성\n",
        "    \"\"\"\n",
        "    def __init__(self, docs:List[str], word2id:Dict[str,int], window_size:int=5):\n",
        "        self.docs = docs#None\n",
        "        self.word2id = word2id#None\n",
        "        self.window_size = window_size#None\n",
        "        self.pairs = self.make_pair()\n",
        "    \n",
        "    def make_pair(self):\n",
        "        from keras.preprocessing.sequence import skipgrams\n",
        "        \"\"\"\n",
        "        (target, context) 형식의 Skip-gram pair 데이터 셋 생성 \n",
        "        \"\"\"\n",
        "        skip_grams = [skipgrams(wid, len(docs), self.window_size) for wid in word2id]\n",
        "        pairs = skip_grams[0][0]#None\n",
        "\n",
        "        return pairs\n",
        "        \n",
        "    def __len__(self):\n",
        "        self.N_pairs=len(self.make_pair())#None\n",
        "        return self.N_pairs\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        from sklearn.feature_extraction.text import CountVectorizer\n",
        "        count_vectorizer = CountVectorizer()\n",
        "        count_vectorizer.fit(docs) \n",
        "        self.idx=count_vectorizer.vocabulary_#None\n",
        "        return self.idx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 181,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-19T14:33:38.945361Z",
          "start_time": "2022-02-19T14:33:38.385577Z"
        },
        "id": "YntOw2q94WSm"
      },
      "outputs": [],
      "source": [
        "dataset = CustomDataset(docs, word2id, window_size=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 182,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-19T14:33:38.949614Z",
          "start_time": "2022-02-19T14:33:38.946663Z"
        },
        "id": "-RpNbAjk4WSn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aad22c82-5c36-48ee-b710-3c7b4d3147e5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24"
            ]
          },
          "metadata": {},
          "execution_count": 182
        }
      ],
      "source": [
        "len(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 183,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-19T14:33:43.072635Z",
          "start_time": "2022-02-19T14:33:43.069526Z"
        },
        "id": "1FBwcL4H4WSn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fdaeb149-ebd7-48bb-cf99-b671ea9990c3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'캐릭터들': 1828,\n",
              " '개연성': 94,\n",
              " '긴장': 257,\n",
              " '재미': 1592,\n",
              " '모든컷': 629,\n",
              " '완벽': 1364,\n",
              " '하고': 1923,\n",
              " '자연': 1550,\n",
              " '스럽': 963,\n",
              " '굉장': 184,\n",
              " '진짜': 1750,\n",
              " '아니어떻': 1079,\n",
              " '이렇': 1468,\n",
              " '재미있': 1597,\n",
              " '원작': 1401,\n",
              " '제대로': 1671,\n",
              " '살리': 864,\n",
              " '못하': 650,\n",
              " '었지만': 1247,\n",
              " '의미': 1441,\n",
              " '영화': 1318,\n",
              " '시놉시스': 1001,\n",
              " '아나': 1073,\n",
              " '처음': 1784,\n",
              " '부터': 792,\n",
              " '까지': 268,\n",
              " '답답': 422,\n",
              " '느낌': 371,\n",
              " '미국': 682,\n",
              " '해병대': 1961,\n",
              " '선전': 895,\n",
              " '아니': 1077,\n",
              " '뻔하': 834,\n",
              " '내용': 319,\n",
              " '지루해서': 1737,\n",
              " '미치': 692,\n",
              " '아다': 1082,\n",
              " '블랙': 811,\n",
              " '이영화': 1489,\n",
              " '에서': 1257,\n",
              " '처음봤는데': 1785,\n",
              " '완전': 1366,\n",
              " 'ㅋㅋ': 20,\n",
              " '폭력영화': 1911,\n",
              " '자극적': 1541,\n",
              " '실험적': 1032,\n",
              " '예술인': 1340,\n",
              " '미스터리스릴러': 690,\n",
              " '정말': 1659,\n",
              " '어설프': 1189,\n",
              " '손발': 941,\n",
              " '오그라들': 1346,\n",
              " '세남자': 916,\n",
              " '아기바구니': 1069,\n",
              " '잖아': 1562,\n",
              " '평점': 1904,\n",
              " '낚여': 294,\n",
              " '아ㄴ데': 1062,\n",
              " '아깝': 1071,\n",
              " '쓰레기영화': 1056,\n",
              " '한동안': 1939,\n",
              " '일본영화': 1526,\n",
              " '안볼듯': 1128,\n",
              " 'ㅡㅡ': 38,\n",
              " '잔잔한': 1561,\n",
              " '감동': 72,\n",
              " '영화네여엔딩송': 1323,\n",
              " '맘에드네': 592,\n",
              " '감독': 67,\n",
              " '도전': 458,\n",
              " '정신': 1663,\n",
              " '박수': 706,\n",
              " '이제': 1493,\n",
              " '그만하': 226,\n",
              " '망작': 594,\n",
              " '전형적': 1646,\n",
              " '한국식': 1934,\n",
              " '신파': 1022,\n",
              " '깡패영화': 271,\n",
              " '이딴걸': 1454,\n",
              " '여러번': 1272,\n",
              " 'ㄴ다는': 3,\n",
              " '영알못': 1310,\n",
              " '새키들': 877,\n",
              " 'ㅈㅅ추천': 17,\n",
              " '작위적': 1555,\n",
              " '스토리': 974,\n",
              " '수시': 948,\n",
              " '변하': 748,\n",
              " '인물성격': 1512,\n",
              " '설정': 900,\n",
              " '고루': 148,\n",
              " '갖추': 82,\n",
              " '눈요기': 365,\n",
              " '거리': 102,\n",
              " '소재': 939,\n",
              " '선택': 896,\n",
              " '었다면': 1237,\n",
              " '만큼': 580,\n",
              " '시나리오': 999,\n",
              " '성의껏': 908,\n",
              " '어라': 1177,\n",
              " '제발': 1675,\n",
              " '아이러니': 1104,\n",
              " '시청률': 1011,\n",
              " '었는데': 1232,\n",
              " '액션': 1154,\n",
              " '시퀀스': 1012,\n",
              " '보물': 758,\n",
              " '방금': 722,\n",
              " '극장': 232,\n",
              " '아ㅁ': 1065,\n",
              " '굿잡': 201,\n",
              " '최악': 1805,\n",
              " '아무런': 1094,\n",
              " '반전': 714,\n",
              " '남자': 305,\n",
              " '아까움': 1070,\n",
              " '다음주': 405,\n",
              " '마지막회': 562,\n",
              " '라니': 516,\n",
              " '왜이렇게빨리': 1371,\n",
              " '끝나는지ㅠㅠㅠㅠ민호제발살아서돌아오길ㅠㅠㅠㅠ': 277,\n",
              " '어리': 1182,\n",
              " '아ㄹ': 1063,\n",
              " '유치': 1419,\n",
              " '었었다는': 1242,\n",
              " '장난': 1580,\n",
              " '안까': 1119,\n",
              " '동네': 467,\n",
              " '양아치': 1165,\n",
              " '고삐': 153,\n",
              " '한테': 1947,\n",
              " '비디오': 815,\n",
              " '카메라': 1825,\n",
              " '하나': 1925,\n",
              " '오래': 1349,\n",
              " '이거보단': 1446,\n",
              " 'ㅉㅉ': 19,\n",
              " '인도영화': 1507,\n",
              " '항상': 1958,\n",
              " '교훈': 189,\n",
              " '아미르': 1096,\n",
              " '나온영화': 289,\n",
              " '그러': 217,\n",
              " 'ㄴ가': 0,\n",
              " '재밌다': 1610,\n",
              " 'ㅋ손현좋아': 28,\n",
              " '밴드': 738,\n",
              " '기타': 255,\n",
              " '미만준건': 689,\n",
              " '알바들인': 1142,\n",
              " '버리': 739,\n",
              " '었던': 1239,\n",
              " '유년': 1409,\n",
              " '시절': 1010,\n",
              " '다시금': 393,\n",
              " '만들': 571,\n",
              " '마력': 549,\n",
              " '쓰레기': 1054,\n",
              " '점주는것들': 1653,\n",
              " '한국영화': 1935,\n",
              " '점주': 1652,\n",
              " '애국': 1147,\n",
              " '자식들': 1547,\n",
              " '한숨': 1943,\n",
              " '시ㄴ': 990,\n",
              " '함성': 1954,\n",
              " '으로': 1425,\n",
              " '열정대신': 1305,\n",
              " '죽기살기': 1715,\n",
              " '우리': 1383,\n",
              " '누구': 357,\n",
              " '용감': 1381,\n",
              " '녀석': 336,\n",
              " '녀석들': 337,\n",
              " '누군가': 358,\n",
              " '여기': 1270,\n",
              " '어딘가': 1170,\n",
              " '이런건': 1463,\n",
              " '벅스버니나실베스터': 742,\n",
              " '트위티미키': 1868,\n",
              " '마우스플루토구피대피': 553,\n",
              " '상징되는메이저작품들수준에는멀리': 870,\n",
              " '못미치': 643,\n",
              " '평범작': 1901,\n",
              " '오래전': 1350,\n",
              " '아직': 1111,\n",
              " '기억': 250,\n",
              " '보영언니': 763,\n",
              " '화이팅': 1990,\n",
              " '뉴욕': 368,\n",
              " '연극': 1292,\n",
              " '기분': 247,\n",
              " '이해': 1499,\n",
              " '무리': 658,\n",
              " '지만': 1738,\n",
              " '매료': 598,\n",
              " '연기력': 1294,\n",
              " '구성력': 198,\n",
              " '반하': 716,\n",
              " '관심': 175,\n",
              " '사랑': 848,\n",
              " '원하': 1402,\n",
              " '날개': 298,\n",
              " '사람': 847,\n",
              " '비상': 817,\n",
              " '박중훈': 709,\n",
              " '역시': 1288,\n",
              " '에수비에스': 1260,\n",
              " '막장드라마': 567,\n",
              " '임꺽정같': 1532,\n",
              " '사극': 843,\n",
              " '한편': 1949,\n",
              " '이라도': 1456,\n",
              " '었으면': 1244,\n",
              " '을텐데': 1435,\n",
              " '생각': 878,\n",
              " '욕심': 1380,\n",
              " '이런': 1461,\n",
              " '보이': 764,\n",
              " '다른': 387,\n",
              " '명작영화': 619,\n",
              " '싫어하는건': 1034,\n",
              " 'ㄴ데': 5,\n",
              " '도저히': 457,\n",
              " '일밤': 1521,\n",
              " '깨끗': 272,\n",
              " '순수': 954,\n",
              " '모르': 630,\n",
              " '겠어': 121,\n",
              " '재미면': 1594,\n",
              " '에서는': 1258,\n",
              " '한테는': 1948,\n",
              " '로이': 534,\n",
              " '진장감있': 1747,\n",
              " '성장드라마': 913,\n",
              " '이가': 1443,\n",
              " '연기를왜이렇': 1295,\n",
              " '믿음': 697,\n",
              " '앞세우': 1146,\n",
              " '나누': 280,\n",
              " '는게': 375,\n",
              " '언제': 1210,\n",
              " '참되': 1778,\n",
              " '신자': 1021,\n",
              " '모습': 631,\n",
              " 'ㅂ니까': 13,\n",
              " '에는': 1254,\n",
              " '불협화음': 806,\n",
              " '용서': 1382,\n",
              " '승화': 989,\n",
              " '극복': 231,\n",
              " '주님': 1705,\n",
              " '으면': 1430,\n",
              " '램프': 521,\n",
              " '요점': 1377,\n",
              " '마냥': 546,\n",
              " '만사': 573,\n",
              " '해결': 1959,\n",
              " '웃기': 1395,\n",
              " '노릇': 342,\n",
              " 'ㅂ니다': 14,\n",
              " '배우들': 729,\n",
              " '연기': 1293,\n",
              " '연출': 1300,\n",
              " '전부': 1640,\n",
              " '단막극': 412,\n",
              " '매력': 597,\n",
              " '드라마': 481,\n",
              " '최고': 1801,\n",
              " '츤츤의정석': 1816,\n",
              " '너무': 326,\n",
              " '재밌어': 1614,\n",
              " 'ㅋㅋㅋ': 21,\n",
              " '기대안': 244,\n",
              " 'ㄹ까': 10,\n",
              " '마음': 554,\n",
              " '배우': 728,\n",
              " '없이': 1224,\n",
              " '빠져듬': 829,\n",
              " '복사기': 767,\n",
              " '디카': 494,\n",
              " '이필모': 1498,\n",
              " '심의영': 1037,\n",
              " '다가': 381,\n",
              " '영화끝나': 1322,\n",
              " '목소리': 637,\n",
              " '열연': 1303,\n",
              " '셨음': 926,\n",
              " 'ㅎㅎ': 29,\n",
              " '엉성함': 1250,\n",
              " '통속적': 1863,\n",
              " '러브스토리': 523,\n",
              " '스릴러': 965,\n",
              " '전설': 1641,\n",
              " '애니': 1149,\n",
              " '아군': 1068,\n",
              " '아름답': 1087,\n",
              " '하지만': 1930,\n",
              " '지루': 1735,\n",
              " '그렇': 221,\n",
              " '쇠맛': 944,\n",
              " '역묶음질': 1286,\n",
              " '모두': 626,\n",
              " '만족': 577,\n",
              " '시키': 1013,\n",
              " '수작': 950,\n",
              " '후반': 2000,\n",
              " '여주인공': 1282,\n",
              " '초반': 1796,\n",
              " '주인공': 1712,\n",
              " '짝사랑': 1763,\n",
              " '귀엽': 204,\n",
              " '여배우': 1273,\n",
              " '매우': 600,\n",
              " '굿굿': 200,\n",
              " '포스터': 1909,\n",
              " '이상하넼ㅋ': 1482,\n",
              " '배경': 724,\n",
              " '이랑': 1459,\n",
              " '인물': 1510,\n",
              " '어색': 1185,\n",
              " '자체': 1552,\n",
              " '팽이들': 1889,\n",
              " '지나': 1730,\n",
              " '슈슈슉': 961,\n",
              " '떨어짐ㅋㅋ': 502,\n",
              " '필요': 1921,\n",
              " '명작': 618,\n",
              " '최강': 1800,\n",
              " '보이스': 765,\n",
              " '현영': 1978,\n",
              " '아존나우껴': 1106,\n",
              " 'ㅋㅋㅋㅋㅋ': 23,\n",
              " '그레고리펙': 222,\n",
              " '표정연기': 1915,\n",
              " '이리': 1473,\n",
              " '허접한': 1971,\n",
              " '치밀': 1818,\n",
              " '설득력': 898,\n",
              " '게다': 113,\n",
              " '하나님쪽': 1926,\n",
              " '저리': 1625,\n",
              " '무력한': 657,\n",
              " '드라마스페셜': 483,\n",
              " '섬뜩': 901,\n",
              " '공포영화': 164,\n",
              " '분류': 794,\n",
              " '없을정도': 1222,\n",
              " '지나치': 1731,\n",
              " '지루함': 1736,\n",
              " '아라': 1086,\n",
              " '마지막': 561,\n",
              " '뒷모습': 479,\n",
              " '백프': 737,\n",
              " '드러나': 484,\n",
              " '잘못': 1568,\n",
              " '에만': 1256,\n",
              " '미안': 691,\n",
              " 'ㅠㅠ': 34,\n",
              " 'ㅋㅋㅋㅋ': 22,\n",
              " '진심': 1746,\n",
              " '으면서': 1431,\n",
              " '메뚜기': 612,\n",
              " '같이': 83,\n",
              " '생긴애': 882,\n",
              " '따르': 496,\n",
              " '면서': 616,\n",
              " '볼까말까': 774,\n",
              " '고민': 151,\n",
              " '계신분': 145,\n",
              " '으시면': 1433,\n",
              " '개콘보다': 100,\n",
              " '아낰ㅋㅋㅋ': 1075,\n",
              " '내시간': 317,\n",
              " '슠ㅋㅋㅋ퐠ㅋㅋㅋㅋㅋ': 962,\n",
              " '짱잼씀': 1766,\n",
              " '아빠': 1097,\n",
              " '선생님': 893,\n",
              " '영화판': 1332,\n",
              " '보다': 755,\n",
              " '긍정적': 240,\n",
              " '적극적': 1632,\n",
              " '나와요전': 290,\n",
              " '그래서': 216,\n",
              " '아아': 1100,\n",
              " '그리고': 224,\n",
              " '결말': 131,\n",
              " '해피엔딩': 1964,\n",
              " '그런데': 220,\n",
              " '더빙': 440,\n",
              " '원래': 1397,\n",
              " '언어': 1209,\n",
              " '그대로': 213,\n",
              " '스토어': 978,\n",
              " '더빙판': 441,\n",
              " '아쉽': 1099,\n",
              " '어요': 1191,\n",
              " '와는': 1363,\n",
              " '전혀': 1645,\n",
              " '상관': 866,\n",
              " '후회': 2003,\n",
              " '시간아깝지': 997,\n",
              " '잘봤습니': 1570,\n",
              " '끔찍': 275,\n",
              " '여주': 1281,\n",
              " '제외': 1679,\n",
              " '못봐주겠음': 647,\n",
              " '허술': 1970,\n",
              " '어색한': 1186,\n",
              " '영화구성': 1321,\n",
              " '뜨끔': 511,\n",
              " '러브라인': 522,\n",
              " '몰입': 638,\n",
              " '무척': 669,\n",
              " '힘들': 2017,\n",
              " '우리진짜솔직해지자': 1385,\n",
              " '사랑해': 852,\n",
              " '우아': 1386,\n",
              " '성장': 912,\n",
              " '그녀': 211,\n",
              " '그냥': 209,\n",
              " '주연': 1708,\n",
              " '라는': 515,\n",
              " '만으로만': 575,\n",
              " '별점': 750,\n",
              " '요즘': 1378,\n",
              " '무섭진않지': 662,\n",
              " '여전히': 1280,\n",
              " '다시한번': 396,\n",
              " '이런영화': 1465,\n",
              " '을까': 1434,\n",
              " '추억': 1810,\n",
              " '담기': 420,\n",
              " '의대다니기때문': 1439,\n",
              " '더라': 438,\n",
              " 'ㅉㅈ': 18,\n",
              " '효민나오네': 1998,\n",
              " '안봐': 1129,\n",
              " '기대': 243,\n",
              " '실망': 1026,\n",
              " '었습니다': 1240,\n",
              " '평론가분': 1899,\n",
              " '처럼': 1783,\n",
              " '시작': 1009,\n",
              " '렬했습니': 529,\n",
              " '나치': 292,\n",
              " '언급': 1206,\n",
              " '거대': 101,\n",
              " '비전은보이지않고': 819,\n",
              " '여러명이': 1271,\n",
              " '소꿉놀이': 929,\n",
              " '아ㅂ니다': 1066,\n",
              " '영활보는것보단': 1334,\n",
              " '게이': 115,\n",
              " '말그대': 587,\n",
              " '남자이야기': 308,\n",
              " '민수형님': 695,\n",
              " '어우': 1192,\n",
              " '멋지': 610,\n",
              " '예전': 1342,\n",
              " '본거지': 770,\n",
              " '내겐': 311,\n",
              " '미국코미디': 684,\n",
              " '요소': 1376,\n",
              " '가슴': 47,\n",
              " '설레': 899,\n",
              " '조카': 1691,\n",
              " '마약권하': 552,\n",
              " '사회': 857,\n",
              " '라면': 517,\n",
              " '점수': 1648,\n",
              " '만점': 576,\n",
              " '유느님': 1410,\n",
              " '짜셰사랑하': 1757,\n",
              " '존경해요하하': 1693,\n",
              " '오빠': 1355,\n",
              " 'ㅇ귀엽고개리': 16,\n",
              " '귀엽고지효': 205,\n",
              " '언니': 1207,\n",
              " '이쁘니석진': 1477,\n",
              " '약하': 1163,\n",
              " '긍정적ㅋㅋ': 241,\n",
              " '광수': 180,\n",
              " '힘내': 2015,\n",
              " '어서': 1187,\n",
              " '다행': 411,\n",
              " '짜리': 1755,\n",
              " '김치맨들': 263,\n",
              " '겠나': 116,\n",
              " '고생': 154,\n",
              " '지렁이들': 1734,\n",
              " '여자들': 1278,\n",
              " '주는꼬라지보': 1704,\n",
              " '확실히': 1991,\n",
              " '멍청': 611,\n",
              " '사고수준': 840,\n",
              " '유아수준': 1416,\n",
              " '엉망': 1248,\n",
              " '안타깝': 1136,\n",
              " '이해불': 1500,\n",
              " '가지만': 56,\n",
              " '인간': 1504,\n",
              " '실화라는게': 1033,\n",
              " '충격': 1815,\n",
              " '마이너스': 557,\n",
              " '는지': 378,\n",
              " '궁금': 202,\n",
              " '잤다그냥': 1576,\n",
              " '아이': 1102,\n",
              " '이딴거': 1453,\n",
              " '는거야': 374,\n",
              " '었을': 1245,\n",
              " '간만': 63,\n",
              " '다시': 392,\n",
              " '더럽': 439,\n",
              " '눈치': 366,\n",
              " 'ㄴ다': 2,\n",
              " 'ㅋㅋㅋ이미': 24,\n",
              " 'ㄴ지': 6,\n",
              " '이나': 1450,\n",
              " '앵글': 1158,\n",
              " '부분': 789,\n",
              " '조르': 1684,\n",
              " '쓰래기중': 1053,\n",
              " '쓰래': 1050,\n",
              " '다운받았는대': 401,\n",
              " '삭제': 860,\n",
              " '영화발전': 1325,\n",
              " '후퇴': 2002,\n",
              " '쓰래기영화다': 1052,\n",
              " '원숭이': 1398,\n",
              " '어도': 1168,\n",
              " '잘만들겟다': 1565,\n",
              " '감독들': 69,\n",
              " '말두': 588,\n",
              " '안되': 1122,\n",
              " '형성': 1980,\n",
              " '둥지': 477,\n",
              " '한마리': 1940,\n",
              " '작살': 1554,\n",
              " '죽이': 1716,\n",
              " '도록': 450,\n",
              " '억지로': 1202,\n",
              " '대사': 429,\n",
              " '황당': 1992,\n",
              " '채우': 1780,\n",
              " '에휴': 1265,\n",
              " '저주': 1627,\n",
              " '어떤면에선': 1174,\n",
              " '영웅본색': 1313,\n",
              " '초월': 1798,\n",
              " '후반부': 2001,\n",
              " '복선': 768,\n",
              " '깜빡': 270,\n",
              " '아네': 1076,\n",
              " '실제': 1029,\n",
              " '허구': 1967,\n",
              " '경계': 139,\n",
              " '오가': 1345,\n",
              " '주제': 1714,\n",
              " '표현': 1916,\n",
              " '습니다': 987,\n",
              " '개봉후': 92,\n",
              " '며칠만': 615,\n",
              " '아닌가': 1081,\n",
              " '지금': 1729,\n",
              " '개봉': 90,\n",
              " '수많': 947,\n",
              " '멜로': 614,\n",
              " '영화들': 1324,\n",
              " '깊이': 266,\n",
              " '최고였어ㅠ': 1802,\n",
              " '당신': 423,\n",
              " '사랑은나': 850,\n",
              " '마음을열어주는열쇠입니': 556,\n",
              " '죄의식': 1703,\n",
              " '치유': 1819,\n",
              " '호세': 1983,\n",
              " '예수': 1338,\n",
              " '생각나': 879,\n",
              " '청개구리': 1790,\n",
              " '어른': 1181,\n",
              " '서도': 884,\n",
              " '동화책': 474,\n",
              " '분위기': 799,\n",
              " '신기원': 1017,\n",
              " '스피시즈': 983,\n",
              " '재밌고': 1606,\n",
              " '흥미진진': 2011,\n",
              " '잘봤어요': 1571,\n",
              " '라서': 519,\n",
              " '살넘고': 863,\n",
              " '성인': 909,\n",
              " '어서야': 1188,\n",
              " '탄탄': 1852,\n",
              " '잘하': 1573,\n",
              " '시네요': 1000,\n",
              " '아ㄴ': 1061,\n",
              " '조연': 1688,\n",
              " '여자배': 1279,\n",
              " '들중': 489,\n",
              " '내스탈': 316,\n",
              " '있오': 1538,\n",
              " '이상': 1479,\n",
              " '가치': 57,\n",
              " '솔까': 942,\n",
              " '물론': 676,\n",
              " '억지스런부분': 1204,\n",
              " '관심의차이': 176,\n",
              " '관점의차이이지': 178,\n",
              " '묘사': 651,\n",
              " '이정도': 1492,\n",
              " '훌륭': 2006,\n",
              " '다만': 388,\n",
              " '탁월': 1851,\n",
              " '비하': 822,\n",
              " '다소': 391,\n",
              " '아쉬운점': 1098,\n",
              " '드리오': 486,\n",
              " '리라': 540,\n",
              " '황우슬혜': 1995,\n",
              " '느끼함': 370,\n",
              " '오늘': 1348,\n",
              " '조조': 1689,\n",
              " '뛰쳐나갈번함': 509,\n",
              " '액션최고': 1156,\n",
              " '보셔도좋습니다': 761,\n",
              " '않으실거': 1138,\n",
              " '니까': 380,\n",
              " '가지': 55,\n",
              " '필립': 1920,\n",
              " '카우프만': 1826,\n",
              " '마이클크라이튼의라이징선': 558,\n",
              " '완전히': 1367,\n",
              " '망쳐놓두만': 595,\n",
              " '예술영화로가': 1339,\n",
              " '올해': 1362,\n",
              " '영화중': 1331,\n",
              " '가장': 52,\n",
              " '나찌': 291,\n",
              " '에게': 1251,\n",
              " '쫓기': 1768,\n",
              " '드리': 485,\n",
              " '아프리카일동': 1116,\n",
              " '프랑스': 1917,\n",
              " '서정적': 890,\n",
              " '뭔가': 678,\n",
              " '파격': 1877,\n",
              " '텐데': 1861,\n",
              " '막장간다': 566,\n",
              " '이젠': 1495,\n",
              " '더이상': 442,\n",
              " '못보': 644,\n",
              " '우엨': 1387,\n",
              " '네이버': 335,\n",
              " '줄거리애': 1719,\n",
              " '알려쥬ㅓㅆ어': 1139,\n",
              " '또다른': 503,\n",
              " '영웅': 1312,\n",
              " '케이팝스타': 1835,\n",
              " '왜이래': 1369,\n",
              " '합체': 1956,\n",
              " '하고썸띵': 1924,\n",
              " '오바였음내': 1354,\n",
              " '노래': 340,\n",
              " '잘아는건': 1572,\n",
              " '그래도': 215,\n",
              " '합체랑': 1957,\n",
              " '썸띵': 1049,\n",
              " '탈락한': 1853,\n",
              " '오바': 1353,\n",
              " '었음': 1246,\n",
              " '볼맛': 778,\n",
              " '달리': 418,\n",
              " '전개': 1634,\n",
              " '상당히': 867,\n",
              " '한국의': 1936,\n",
              " '막장': 565,\n",
              " '굉장히': 185,\n",
              " '힘듦': 2018,\n",
              " '흥미': 2010,\n",
              " '무조건': 668,\n",
              " '시간': 994,\n",
              " 'ㅡㅡ스토리': 39,\n",
              " '개병맛': 89,\n",
              " '네놈': 332,\n",
              " '저평가': 1630,\n",
              " '올리': 1361,\n",
              " '나름': 282,\n",
              " '재밌': 1604,\n",
              " '원영': 1399,\n",
              " '이해안': 1501,\n",
              " '남자변신한': 307,\n",
              " '못생기': 649,\n",
              " '장국영이': 1579,\n",
              " '장국영귀요미': 1578,\n",
              " '끝나': 276,\n",
              " '배트맨': 734,\n",
              " '한대': 1938,\n",
              " '본다그냥': 771,\n",
              " '백문이불여일견': 735,\n",
              " '사정없이': 855,\n",
              " '후려갈기': 1999,\n",
              " '돌아서': 465,\n",
              " '레알': 525,\n",
              " '아무것': 1093,\n",
              " '이거': 1444,\n",
              " '레이싱': 526,\n",
              " '자동차': 1544,\n",
              " '기억나': 251,\n",
              " '혼자': 1987,\n",
              " '치고': 1817,\n",
              " '장구치': 1577,\n",
              " '다하': 410,\n",
              " '티모시': 1874,\n",
              " '달튼': 419,\n",
              " '배역': 727,\n",
              " '어울리': 1193,\n",
              " '금요일': 238,\n",
              " '얼마나': 1213,\n",
              " '슬래셔인': 985,\n",
              " '비교': 813,\n",
              " '체험': 1791,\n",
              " '저급': 1623,\n",
              " '유사품': 1413,\n",
              " '특유': 1871,\n",
              " '감성': 76,\n",
              " '실컷': 1030,\n",
              " '었다': 1234,\n",
              " '엉성': 1249,\n",
              " '아지만': 1110,\n",
              " '상어영화': 869,\n",
              " '자부': 1545,\n",
              " '시대': 1003,\n",
              " '뛰어넘': 508,\n",
              " '는다': 376,\n",
              " '고인': 156,\n",
              " '모든': 628,\n",
              " '간간히': 60,\n",
              " '노출씬': 348,\n",
              " '버티': 741,\n",
              " '나마': 283,\n",
              " '조금이마': 1683,\n",
              " '모자이크': 633,\n",
              " '열빡치': 1302,\n",
              " '소름': 931,\n",
              " '친절': 1822,\n",
              " '엔딩': 1267,\n",
              " '참기힘들다': 1777,\n",
              " '엔간치좀': 1266,\n",
              " '질질끄세여ㅡㅡ': 1753,\n",
              " '막장드라마ㅡㅡ': 568,\n",
              " '빨리': 830,\n",
              " '새로운프로보고싶네진짜': 874,\n",
              " '재미없으ㅡㅡ': 1596,\n",
              " 'ㄹ수록': 11,\n",
              " '내용전개도억지': 321,\n",
              " '시간끄는듯한': 995,\n",
              " '내용ㅡㅡ': 320,\n",
              " '짜증': 1759,\n",
              " '뻔뻔': 833,\n",
              " '흥행': 2012,\n",
              " '었단': 1238,\n",
              " '싸이코물': 1046,\n",
              " '으로는': 1426,\n",
              " '유선방송케이블': 1415,\n",
              " '돈주고': 463,\n",
              " '못보겠더군요': 645,\n",
              " '미리': 688,\n",
              " '돈내고조조': 462,\n",
              " '봤던건': 786,\n",
              " '아일랜드': 1105,\n",
              " '코드': 1839,\n",
              " '한국': 1933,\n",
              " '김한민': 264,\n",
              " '최종변기활': 1807,\n",
              " '짝퉁': 1764,\n",
              " '베낄걸': 747,\n",
              " '베껴야지ㅣ': 746,\n",
              " '남는건': 301,\n",
              " '겠습니다': 120,\n",
              " 'ㅜㅜ': 31,\n",
              " '안맞고': 1126,\n",
              " '이상해': 1483,\n",
              " '초등학교': 1793,\n",
              " '저학년때': 1631,\n",
              " '개봉한영화': 91,\n",
              " '어렴풋이': 1179,\n",
              " '몇장면만': 625,\n",
              " '커서': 1833,\n",
              " '다시보니': 394,\n",
              " '새롭네요': 876,\n",
              " '구라꾼': 194,\n",
              " '었구만': 1228,\n",
              " '다면': 389,\n",
              " '아이들': 1103,\n",
              " '없는건': 1217,\n",
              " '슬프': 986,\n",
              " '서양애': 888,\n",
              " '소유진': 936,\n",
              " '넘짱나': 330,\n",
              " '드라마넘넘질질끈다': 482,\n",
              " '소유진좀그만': 937,\n",
              " '좀나오게부탁': 1696,\n",
              " '인제딸인거밝히': 1517,\n",
              " '소유진좀나오지마': 938,\n",
              " '주윤발': 1711,\n",
              " '단역': 415,\n",
              " '사기영화': 845,\n",
              " '평론가들': 1898,\n",
              " '컷다': 1834,\n",
              " '신랑': 1019,\n",
              " '어쩌': 1197,\n",
              " '느리': 372,\n",
              " '짜증남': 1761,\n",
              " '작가누구냐': 1553,\n",
              " '보라는거': 757,\n",
              " '스타일리시한': 971,\n",
              " '영상': 1309,\n",
              " '음악': 1437,\n",
              " '무엇': 667,\n",
              " '샤이아': 883,\n",
              " '라보프는': 518,\n",
              " '역할': 1289,\n",
              " '매즈': 602,\n",
              " '미켈슨': 693,\n",
              " '입아픈': 1533,\n",
              " '최민수': 1804,\n",
              " '김혜선': 265,\n",
              " '눈맞으': 361,\n",
              " '기다리': 242,\n",
              " '었나': 1230,\n",
              " '만화': 582,\n",
              " '거북한': 105,\n",
              " '에겐': 1253,\n",
              " '승질난다': 988,\n",
              " '문어발에소주생각나': 670,\n",
              " '영화임': 1330,\n",
              " '개막장': 87,\n",
              " '무식': 666,\n",
              " '과도한': 169,\n",
              " '롱테이크때문': 536,\n",
              " '울렁거리': 1391,\n",
              " '재밌었습니다': 1618,\n",
              " '네요': 334,\n",
              " '좋아용': 1698,\n",
              " '잔인': 1559,\n",
              " '산만': 862,\n",
              " '도대체': 449,\n",
              " '었는지': 1233,\n",
              " '겠다': 119,\n",
              " '리메이크': 541,\n",
              " '이야기': 1486,\n",
              " '무더기': 654,\n",
              " '눈치채': 367,\n",
              " '었어야': 1241,\n",
              " '월광': 1403,\n",
              " '소나타': 930,\n",
              " '피아노곡': 1918,\n",
              " '평생': 1902,\n",
              " '남기': 300,\n",
              " '정이건이출연한': 1667,\n",
              " '위안에는들어갈영화': 1404,\n",
              " '무겁': 652,\n",
              " '마치': 563,\n",
              " '동화': 473,\n",
              " '심플한': 1040,\n",
              " '어떻': 1176,\n",
              " '단순': 414,\n",
              " '수록': 946,\n",
              " '다는': 382,\n",
              " '만화영화': 583,\n",
              " '참고': 1776,\n",
              " '재밋': 1598,\n",
              " '호호': 1984,\n",
              " '으로서': 1428,\n",
              " '아니엇으': 1080,\n",
              " '아아아아': 1101,\n",
              " '작품이긴한데': 1557,\n",
              " '루즈해서': 537,\n",
              " '힘드렀음': 2016,\n",
              " '리들리': 539,\n",
              " '스콧': 968,\n",
              " '약빨고': 1162,\n",
              " '뒤죽박죽': 478,\n",
              " '실감': 1024,\n",
              " '이건뭐': 1447,\n",
              " '마스터': 551,\n",
              " '치프': 1820,\n",
              " '모텐슨': 634,\n",
              " '었네': 1231,\n",
              " '스텝롤': 973,\n",
              " '놀라': 349,\n",
              " '암튼': 1144,\n",
              " '였음': 1308,\n",
              " '데미무': 445,\n",
              " '일단': 1519,\n",
              " '안어울림': 1132,\n",
              " '전문성우': 1639,\n",
              " '으시고': 1432,\n",
              " '경험이': 141,\n",
              " '인기몰이': 1506,\n",
              " '급급': 239,\n",
              " '성우': 907,\n",
              " '주연자리': 1709,\n",
              " '쓰시는거': 1058,\n",
              " '애니메이션': 1150,\n",
              " '장르': 1583,\n",
              " '가볍': 46,\n",
              " '시는게': 1002,\n",
              " '아프': 1114,\n",
              " '언제쯤': 1211,\n",
              " '빛을내게될까요': 827,\n",
              " '불확실': 807,\n",
              " '미래에대한': 687,\n",
              " '노력': 341,\n",
              " '그러나': 218,\n",
              " '냉정': 325,\n",
              " '현실': 1975,\n",
              " '유관순': 1408,\n",
              " '살인마귀신아님': 865,\n",
              " '아나아나결말머냐': 1074,\n",
              " '김범뒤지냐사냐': 260,\n",
              " '감독누구': 68,\n",
              " '오ㅓㅏ': 1344,\n",
              " '시기': 998,\n",
              " '감동ㅎㅎㅎ': 73,\n",
              " '엔딩크레딧': 1269,\n",
              " '황홀': 1996,\n",
              " '혹은': 1985,\n",
              " '담백': 421,\n",
              " '차분': 1773,\n",
              " '아주': 1107,\n",
              " '리어': 544,\n",
              " '캐스팅': 1830,\n",
              " '못살리나': 648,\n",
              " '팝콘': 1884,\n",
              " '무비': 659,\n",
              " '팝콘먹': 1885,\n",
              " '즐겁': 1727,\n",
              " '결혼': 137,\n",
              " '말한마디': 591,\n",
              " '남의결혼식': 304,\n",
              " '자기반성연설ㅡ': 1542,\n",
              " 'ㅡ최악': 40,\n",
              " '주변사람들': 1707,\n",
              " '재밋고': 1600,\n",
              " '괜찮': 181,\n",
              " '소개': 927,\n",
              " '다르': 386,\n",
              " '순위': 956,\n",
              " '출연진': 1814,\n",
              " '위하': 1405,\n",
              " '태어났다해': 1857,\n",
              " '과언': 171,\n",
              " '태희님': 1858,\n",
              " '팀버튼': 1876,\n",
              " '어린아이': 1183,\n",
              " '작품': 1556,\n",
              " '이란': 1458,\n",
              " '결코': 136,\n",
              " '장면': 1584,\n",
              " '마다': 547,\n",
              " '숨결': 957,\n",
              " '느끼': 369,\n",
              " '구두': 193,\n",
              " '무너지': 653,\n",
              " '식탁': 1016,\n",
              " '탭댄스': 1859,\n",
              " '연애': 1298,\n",
              " '상처': 871,\n",
              " '회복': 1997,\n",
              " '어디': 1169,\n",
              " '장면들이': 1586,\n",
              " '모두들': 627,\n",
              " '차용': 1774,\n",
              " '었기': 1229,\n",
              " '때문': 500,\n",
              " '볼시간': 779,\n",
              " '패스': 1887,\n",
              " '하정우': 1929,\n",
              " '전지현': 1642,\n",
              " '낭비': 310,\n",
              " '외국인배우': 1375,\n",
              " '재연배우': 1619,\n",
              " '왜이렇게': 1370,\n",
              " '영어발음': 1311,\n",
              " '한석규': 1942,\n",
              " '발음': 719,\n",
              " '퀄러티': 1846,\n",
              " '미흡': 694,\n",
              " '짱구': 1765,\n",
              " '이를': 1471,\n",
              " '구하': 199,\n",
              " '려고': 527,\n",
              " '도망': 453,\n",
              " '가족애': 54,\n",
              " '극장판': 233,\n",
              " ...}"
            ]
          },
          "metadata": {},
          "execution_count": 183
        }
      ],
      "source": [
        "dataset[0]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SF0v9BdEUpV4",
        "outputId": "5ce77117-d15a-4426-fe00-79506a0250b7"
      },
      "execution_count": 184,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<__main__.CustomDataset at 0x7fb10cf8b5d0>"
            ]
          },
          "metadata": {},
          "execution_count": 184
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i, pair in enumerate(dataset):\n",
        "  print(i,pair[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "id": "9kSpnFkihqaj",
        "outputId": "822db4ac-c447-4169-f780-8af87d0a1241"
      },
      "execution_count": 199,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-199-b5d580686a44>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpair\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpair\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m: 0"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 193,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-19T14:33:51.040595Z",
          "start_time": "2022-02-19T14:33:51.031473Z"
        },
        "id": "wTAwTjKk4WSn",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "outputId": "3ac33bb3-01a1-4c78-a584-97300307af61"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-193-b14780100785>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"({id2word[pair[0]]}, {id2word[pair[1]]})\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 0"
          ]
        }
      ],
      "source": [
        "# verify (target word, context word)\n",
        "for i, pair in enumerate(dataset):\n",
        "    if i==100:\n",
        "        break\n",
        "    print(f\"({id2word[pair[0]]}, {id2word[pair[1]]})\")\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P0Z50-Dr4WSn"
      },
      "source": [
        "### 위에서 생성한 `dataset`으로 DataLoader  객체 생성\n",
        "- `DataLoader` 클래스로 `train_dataloader`객체를 생성하라. \n",
        "    - 생성자 매개변수와 값\n",
        "        - dataset = 위에서 생성한 dataset\n",
        "        - batch_size = 64\n",
        "        - shuffle = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-19T14:34:02.645176Z",
          "start_time": "2022-02-19T14:34:02.642780Z"
        },
        "id": "GXcAvFB14WSn"
      },
      "outputs": [],
      "source": [
        "train_dataloader = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-19T14:34:02.777322Z",
          "start_time": "2022-02-19T14:34:02.774335Z"
        },
        "id": "4Yfcwi_14WSn"
      },
      "outputs": [],
      "source": [
        "len(train_dataloader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eTs16gsU4WSn"
      },
      "source": [
        "### Negative Sampling 함수 구현\n",
        "- Skip-Gram은 복잡도를 줄이기 위한 방법으로 negative sampling을 사용한다. \n",
        "- `sample_table`이 다음과 같이 주어졌을 때, sample_table에서 랜덤으로 값을 뽑아 (batch_size, n_neg_sample) shape의 matrix를 반환하는 `get_neg_v_negative_sampling()`함수를 구현하라. \n",
        "- Sample Table은 negative distribution을 따른다. \n",
        "    - [negative distribution 설명](https://aegis4048.github.io/optimize_computational_efficiency_of_skip-gram_with_negative_sampling#How-are-negative-samples-drawn?)\n",
        "- 함수 정의\n",
        "    - 입력 매개변수\n",
        "        - batch_size : 배치 사이즈, matrix의 row 개수 \n",
        "        - n_neg_sample : negative sample의 개수, matrix의 column 개수\n",
        "    - 반환값 \n",
        "        - neg_v : 추출된 negative sample (2차원의 리스트)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-19T14:34:11.397509Z",
          "start_time": "2022-02-19T14:34:11.386389Z"
        },
        "id": "PUqIB6dH4WSn",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# negative sample을 추출할 sample table 생성 (해당 코드를 참고)\n",
        "sample_table = []\n",
        "sample_table_size = doc_len\n",
        "\n",
        "# noise distribution 생성\n",
        "alpha = 3/4\n",
        "frequency_list = np.array(list(word2count.values())) ** alpha\n",
        "Z = sum(frequency_list)\n",
        "ratio = frequency_list/Z\n",
        "negative_sample_dist = np.round(ratio*sample_table_size)\n",
        "\n",
        "for wid, c in enumerate(negative_sample_dist):\n",
        "    sample_table.extend([wid]*int(c))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-19T14:34:11.508414Z",
          "start_time": "2022-02-19T14:34:11.505464Z"
        },
        "id": "Wdu8qK8x4WSn"
      },
      "outputs": [],
      "source": [
        "len(sample_table)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-19T14:34:11.656046Z",
          "start_time": "2022-02-19T14:34:11.653325Z"
        },
        "id": "mQIVrOIR4WSn"
      },
      "outputs": [],
      "source": [
        "def get_neg_v_negative_sampling(batch_size:int, n_neg_sample:int):\n",
        "    \"\"\"\n",
        "    위에서 정의한 sample_table에서 (batch_size, n_neg_sample) shape만큼 랜덤 추출해 \"네거티브 샘플 메트릭스\"를 생성\n",
        "    np.random.choice() 함수 활용 (위에서 정의한 sample_table을 함수의 argument로 사용)\n",
        "    \"\"\"\n",
        "    neg_v = None\n",
        "    \n",
        "    return neg_v"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-19T14:34:12.345976Z",
          "start_time": "2022-02-19T14:34:12.333448Z"
        },
        "id": "8wwT4Af04WSo"
      },
      "outputs": [],
      "source": [
        "get_neg_v_negative_sampling(4, 5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nLnDXPvJ4WSo"
      },
      "source": [
        "## Challenge"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B5UubCzK4WSo"
      },
      "source": [
        "### 미니 튜토리얼\n",
        "- 아래 튜토리얼을 따라하며 Skip-Gram 모델의 `forward` 및 `loss` 연산 방식을 이해하자\n",
        "- Reference\n",
        "    - [torch.nn.Embedding](https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html)\n",
        "    - [torch bmm](https://pytorch.org/docs/stable/generated/torch.bmm.html)\n",
        "    - [Skip-Gram negative sampling loss function 설명 영문 블로그](https://aegis4048.github.io/optimize_computational_efficiency_of_skip-gram_with_negative_sampling#Derivation-of-Cost-Function-in-Negative-Sampling)\n",
        "    - [Skip-Gram negative sampling loss function 설명 한글 블로그](https://reniew.github.io/22/)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-19T12:51:46.954048Z",
          "start_time": "2022-02-19T12:51:46.951529Z"
        },
        "id": "IAR68hsY4WSo"
      },
      "outputs": [],
      "source": [
        "# hyper parameter example\n",
        "emb_size = 30000 # vocab size\n",
        "emb_dimension = 300 # word embedding 차원\n",
        "n_neg_sample = 5\n",
        "batch_size = 32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-19T12:51:49.340056Z",
          "start_time": "2022-02-19T12:51:47.300999Z"
        },
        "id": "zzOsVUn94WSo"
      },
      "outputs": [],
      "source": [
        "# 1. Embedding Matrix와 Context Matrix를 생성\n",
        "u_embedding = nn.Embedding(emb_size, emb_dimension, sparse=True).to(device)\n",
        "v_embedding = nn.Embedding(emb_size, emb_dimension, sparse=True).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-19T12:51:49.352240Z",
          "start_time": "2022-02-19T12:51:49.341437Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I7J_ADc44WSo",
        "outputId": "41d82321-be64-4fba-b0f5-a6e027f914d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Target word idx : tensor([24460, 10634,  2864, 23952,  3320, 15187, 19625, 26546, 27339,  3920,\n",
            "        25847,  6023,  5055,  7070,  6291, 10245, 15926,   641, 20178,  4565,\n",
            "         4784, 26715, 16955, 28742, 17947, 19774,  8065, 22605,  3061, 28965,\n",
            "         3056, 17963]) Pos context word idx : tensor([23224,  5636, 23712,  5234,  3991, 17897, 25123, 17938, 19634, 24228,\n",
            "          693,   799, 25457,  1308, 28935, 25696,  5601, 23878,  8312,  1292,\n",
            "        21380, 16974,  9318,  9578, 12915, 29271, 26465, 20572,  2362, 25929,\n",
            "        19754, 29080]) Neg context word idx : [[1282, 10, 10, 727, 58], [544, 26, 1021, 1617, 1137], [119, 3, 453, 404, 436], [376, 3132, 1532, 1204, 281], [2233, 1435, 3145, 2929, 1290], [3159, 408, 2449, 580, 46], [3087, 661, 341, 433, 3], [1138, 1273, 1300, 905, 535], [2744, 183, 1576, 2544, 2131], [574, 1808, 3012, 1438, 897], [898, 3, 1001, 1089, 835], [576, 396, 135, 564, 2746], [2126, 2377, 3126, 1603, 1584], [1216, 914, 74, 3, 1409], [382, 2587, 3080, 144, 1803], [457, 2309, 1268, 395, 805], [293, 1986, 2627, 2856, 1816], [39, 341, 436, 325, 118], [1105, 514, 296, 951, 1933], [2439, 2601, 1925, 195, 44], [1145, 10, 226, 682, 835], [809, 60, 528, 970, 10], [2238, 2061, 1531, 945, 10], [1148, 724, 320, 1334, 151], [632, 638, 35, 1023, 337], [402, 561, 405, 87, 26], [2499, 2029, 47, 3192, 46], [1894, 2766, 1723, 3, 101], [930, 651, 147, 347, 1050], [774, 1808, 874, 1789, 1921], [130, 1686, 1207, 1194, 296], [2124, 1727, 2072, 411, 435]]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# 2. wid(단어 인덱스)를 임의로 생성\n",
        "pos_u = torch.randint(high = emb_size, size = (batch_size,))\n",
        "pos_v = torch.randint(high = emb_size, size = (batch_size,))\n",
        "neg_v = get_neg_v_negative_sampling(batch_size, n_neg_sample)\n",
        "print(f\"Target word idx : {pos_u} Pos context word idx : {pos_v} Neg context word idx : {neg_v}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-19T12:51:49.364020Z",
          "start_time": "2022-02-19T12:51:49.353486Z"
        },
        "id": "4iEG0nCZ4WSo"
      },
      "outputs": [],
      "source": [
        "# 3. tensor로 변환\n",
        "pos_u = Variable(torch.LongTensor(pos_u)).to(device)\n",
        "pos_v = Variable(torch.LongTensor(pos_v)).to(device)\n",
        "neg_v = Variable(torch.LongTensor(neg_v)).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-19T12:51:51.391896Z",
          "start_time": "2022-02-19T12:51:51.387084Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gqbNbajG4WSo",
        "outputId": "10f4812c-c8e4-4c11-bbab-248616a2385f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "shape of pos_u embedding : torch.Size([32, 300])\n",
            " shape of pos_v embedding : torch.Size([32, 300])\n",
            " shape of neg_v embedding : torch.Size([32, 5, 300])\n"
          ]
        }
      ],
      "source": [
        "# 4. wid로 각각의 embedding matrix에서 word embedding 값을 가져오기\n",
        "pos_u = u_embedding(pos_u)\n",
        "pos_v = v_embedding(pos_v)\n",
        "neg_v = v_embedding(neg_v)\n",
        "print(f\"shape of pos_u embedding : {pos_u.shape}\\n shape of pos_v embedding : {pos_v.shape}\\n shape of neg_v embedding : {neg_v.shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-19T12:51:53.121477Z",
          "start_time": "2022-02-19T12:51:52.646148Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uDWUrSwo4WSo",
        "outputId": "fe99394e-e313-4fe2-a47e-04341b634f2f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "shape of pos logits : torch.Size([32])\n",
            "\n",
            "shape of logits : torch.Size([32, 5])\n"
          ]
        }
      ],
      "source": [
        "# 5. dot product \n",
        "pos_score = torch.mul(pos_u, pos_v) # 행렬 element-wise 곱\n",
        "pos_score = torch.sum(pos_score, dim=1)\n",
        "print(f\"shape of pos logits : {pos_score.shape}\\n\")\n",
        "\n",
        "neg_score = torch.bmm(neg_v, pos_u.unsqueeze(dim=2)).squeeze()\n",
        "print(f\"shape of logits : {neg_score.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-19T12:51:53.670418Z",
          "start_time": "2022-02-19T12:51:53.665671Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "adOpcoL54WSo",
        "outputId": "74ac29ee-ce2b-4e54-9182-be0f5189f49c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "pos logits : -241.4199676513672\n",
            "neg logits : -1060.181396484375\n",
            "Loss : 1301.601318359375\n"
          ]
        }
      ],
      "source": [
        "# 6. loss 구하기\n",
        "pos_score = F.logsigmoid(pos_score)\n",
        "neg_score = F.logsigmoid(-1*neg_score) # negative의 logit은 minimize 하기 위해 -1 곱함\n",
        "print(f\"pos logits : {pos_score.sum()}\")\n",
        "print(f\"neg logits : {neg_score.sum()}\")\n",
        "loss = -1 * (torch.sum(pos_score) + torch.sum(neg_score))\n",
        "print(f\"Loss : {loss}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "muEceOGZ4WSo"
      },
      "source": [
        "### Skip-gram 클래스 구현\n",
        "- Skip-Gram 방식으로 단어 embedding을 학습하는 `SkipGram` 클래스를 구현하라.\n",
        "- 클래스 정의\n",
        "    - 생성자(`__init__()` 함수) 입력 매개변수\n",
        "        - `vocab_size` : 사전내 단어 개수\n",
        "        - `emb_dimension` : 엠베딩 크기\n",
        "        - `device` : 연산 장치 종류\n",
        "    - 생성자에서 생성해야할 변수 \n",
        "        - `vocab_size` : 사전내 단어 개수\n",
        "        - `emb_dimension` : 엠베딩 크기\n",
        "        - `u_embedding` : (vocab_size, emb_dimension) 엠베딩 메트릭스 (target_word)\n",
        "        - `v_embedding` : (vocab_size, emb_dimension) 엠베딩 메트릭스 (context_word)\n",
        "    - 메소드\n",
        "        - `init_embedding()` (제공됨)\n",
        "            - 엠베딩 메트릭스 값을 초기화\n",
        "        - `forward()`\n",
        "            - 위 튜토리얼과 같이 dot product를 수행한 후 score를 생성\n",
        "            - loss를 반환 (loss 설명 추가)\n",
        "        - `save_emedding()` (제공됨)\n",
        "            - `u_embedding`의 단어 엠베딩 값을 단어 별로 파일에 저장\n",
        "    - 주의 사항     \n",
        "        - `nn.Module`를 부모 클래스로 상속 받음 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-19T14:34:15.731306Z",
          "start_time": "2022-02-19T14:34:15.721129Z"
        },
        "id": "pnmMamP44WSo"
      },
      "outputs": [],
      "source": [
        "class SkipGram(nn.Module):\n",
        "    def __init__(self, vocab_size:int, emb_dimension:int, device:str):\n",
        "        super(SkipGram, self).__init__()\n",
        "        self.vocab_size = None\n",
        "        self.emb_dimension = None\n",
        "        self.u_embedding = None\n",
        "        self.v_embedding = None\n",
        "        self.init_embedding()\n",
        "    \n",
        "    \n",
        "    def init_embedding(self):\n",
        "        \"\"\"\n",
        "        u_embedding과 v_embedding 메트릭스 값을 초기화\n",
        "        \"\"\"\n",
        "        initrange = 0.5 / self.emb_dimension\n",
        "        self.u_embedding.weight.data.uniform_(-initrange, initrange)\n",
        "        self.v_embedding.weight.data.uniform_(-0, 0)\n",
        "    \n",
        "    \n",
        "    def forward(self, pos_u, pos_v, neg_v):\n",
        "        \"\"\"\n",
        "        dot product를 수행한 후 score를 생성\n",
        "        loss 반환\n",
        "        \"\"\"    \n",
        "            \n",
        "        # 각각의 embedding matrix에서 word embedding 값을 가져오기\n",
        "        pos_u = None\n",
        "        pos_v = None\n",
        "        neg_v = None\n",
        "        \n",
        "        # dot product \n",
        "        pos_score = None\n",
        "        neg_score = None\n",
        "        \n",
        "        # loss 구하기\n",
        "        loss = None\n",
        "\n",
        "        return loss\n",
        "    \n",
        "    def save_embedding(self, id2word, file_name, use_cuda):\n",
        "        \"\"\"\n",
        "        'file_name' 위치에 word와 word_embedding을 line-by로 저장\n",
        "        파일의 첫 줄은 '단어 개수' 그리고 '단어 embedding 사이즈' 값을 입력해야 함\n",
        "        \"\"\"\n",
        "        if use_cuda: # parameter를 gpu 메모리에서 cpu 메모리로 옮김\n",
        "            embedding = self.u_embedding.weight.cpu().data.numpy()\n",
        "        else:\n",
        "            embedding = self.u_embedding.weight.data.numpy()\n",
        "\n",
        "        with open(file_name, 'w') as writer:\n",
        "            # 파일의 첫 줄은 '단어 개수' 그리고 '단어 embedding 사이즈' 값을 입력해야 함\n",
        "            writer.write(f\"{len(id2word)} {embedding.shape[-1]}\\n\")\n",
        "            \n",
        "            for wid, word in id2word.items():\n",
        "                e = embedding[wid]\n",
        "                e = \" \".join([str(e_) for e_ in e])\n",
        "                writer.write(f\"{word} {e}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RqqMo0zL4WSo"
      },
      "source": [
        "## Advanced"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wSWd5gV24WSp"
      },
      "source": [
        "### Skip-Gram 방식의  Word2Vec 클래스 구현\n",
        "- Skip-Gram 방식으로 단어 embedding을 학습하는 `Word2Vec` 클래스를 구현하라.\n",
        "- 클래스 정의\n",
        "    - 생성자(`__init__()`) 입력 매개 변수\n",
        "        - `input_file` : 학습할 문서 리스트\n",
        "        - `output_file_name` : 학습된 word embedding을 저장할 파일 위치\n",
        "        - `device` : 연상 장치 종류\n",
        "        - `emb_dimension` : word embedding 차원\n",
        "        - `batch_size` : 학습 배치 사이즈\n",
        "        - `window_size` : skip-gram 윈도우 사이즈 (context word 개수를 결정)\n",
        "        - `n_neg_sample` : negative sample 개수\n",
        "        - `iteration` : 학습 반복 횟수\n",
        "        - `lr` : learning rate\n",
        "        - `min_count` : 사전에 추가될 단어의 최소 등장 빈도\n",
        "    - 생성자에서 생성해야 할 변수 \n",
        "        - `docs` : 학습할 문서 리스트\n",
        "        - `output_file_name` : 학습된 word embedding을 저장할 파일 위치\n",
        "        - `word2count`, `word2id`, `id2word` : 위에서 구현한 `make_vocab()` 함수의 반환 값\n",
        "        - `device` : 연산 장치 종류\n",
        "        - `emb_size` : vocab의 (unique한) 단어 종류 \n",
        "        - `emb_dimension` : word embedding 차원\n",
        "        - `batch_size` : 학습 배치 사이즈\n",
        "        - `window_size` : skip-gram 윈도우 사이즈 (context word 개수를 결정)\n",
        "        - `n_neg_sample` : negative sample 개수\n",
        "        - `iteration` : 학습 반복 횟수\n",
        "        - `lr` : learning rate\n",
        "        - `model` : `SkipGram` 클래스의 인스턴스\n",
        "        - `optimizer` : `SGD` 클래스의 인스턴스\n",
        "    - 메소드\n",
        "        - `train()`\n",
        "            - 입력 매개변수 \n",
        "                - `train_dataloader`\n",
        "            - Iteration 횟수만큼 input_file 학습 데이터를 학습한다. 매 epoch마다 for loop 돌면서 batch 단위 학습 데이터를 skip gram 모델에 학습함. 학습이 끝나면 word embedding을 output_file_name 파일에 저장.\n",
        "- Reference\n",
        "    - [Optimizer - SGD](https://pytorch.org/docs/stable/generated/torch.optim.SGD.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-19T14:34:20.503555Z",
          "start_time": "2022-02-19T14:34:20.491585Z"
        },
        "id": "Td-GQrqI4WSp"
      },
      "outputs": [],
      "source": [
        "class Word2Vec:\n",
        "    def __init__(self, \n",
        "                input_file: List[str],\n",
        "                output_file_name: str,\n",
        "                 device: str,\n",
        "                 emb_dimension=300,\n",
        "                 batch_size = 64,\n",
        "                 window_size=5,\n",
        "                 n_neg_sample = 5,\n",
        "                 iteration=1,\n",
        "                 lr = 0.02,\n",
        "                 min_count=5):\n",
        "        self.docs = None\n",
        "        self.output_file_name = None\n",
        "        self.word2count, self.word2id, self.id2word = None\n",
        "        self.device = None\n",
        "        self.emb_size = None\n",
        "        self.emb_dimension = None\n",
        "        self.batch_size = None\n",
        "        self.window_size = None\n",
        "        self.n_neg_sample = None\n",
        "        self.iteration = None\n",
        "        self.lr = None\n",
        "        self.model = None\n",
        "        self.optimizer = None # torch.optim.SGD 클래스 사용\n",
        "\n",
        "        # train() 함수에서 만든 임베딩 결과 파일들을 저장할 폴더 생성 (os.makedirs 사용)\n",
        "        None\n",
        "        \n",
        "    \n",
        "    def train(self, train_dataloader):\n",
        "        \n",
        "        # lr 값을 조절하는 스케줄러 인스턴스 변수를 생성\n",
        "        self.scheduler = get_linear_schedule_with_warmup(\n",
        "            optimizer = None,\n",
        "            num_warmup_steps=0,\n",
        "            num_training_steps=None\n",
        "        )\n",
        "        \n",
        "        for epoch in range(self.iteration):\n",
        "            \n",
        "            print(f\"*****Epoch {epoch} Train Start*****\")\n",
        "            print(f\"*****Epoch {epoch} Total Step {len(train_dataloader)}*****\")\n",
        "            total_loss, batch_loss, batch_step = 0,0,0\n",
        "\n",
        "            for step, batch in enumerate(train_dataloader):\n",
        "                batch_step+=1\n",
        "\n",
        "                pos_u, pos_v = batch\n",
        "                # negative data 생성\n",
        "                neg_v = get_neg_v_negative_sampling(pos_u.shape[0], self.n_neg_sample)\n",
        "                \n",
        "                # 데이터를 tensor화 & device 설정\n",
        "                pos_u = None\n",
        "                pos_v = None\n",
        "                neg_v = None\n",
        "\n",
        "                # model의 gradient 초기화\n",
        "                None \n",
        "                # optimizer의 gradient 초기화\n",
        "                None\n",
        "\n",
        "                # forward\n",
        "                loss = None\n",
        "\n",
        "                # loss 계산\n",
        "                None\n",
        "                # optimizer 업데이트\n",
        "                None \n",
        "                # scheduler 업데이트\n",
        "                None\n",
        "\n",
        "                batch_loss += loss.item()\n",
        "                total_loss += loss.item()\n",
        "                \n",
        "                if (step%500 == 0) and (step!=0):\n",
        "                    print(f\"Step: {step} Loss: {batch_loss/batch_step:.4f} lr: {self.optimizer.param_groups[0]['lr']:.4f}\")\n",
        "                    # 변수 초기화    \n",
        "                    batch_loss, batch_step = 0,0\n",
        "            \n",
        "            print(f\"Epoch {epoch} Total Mean Loss : {total_loss/(step+1):.4f}\")\n",
        "            print(f\"*****Epoch {epoch} Train Finished*****\\n\")\n",
        "            \n",
        "            print(f\"*****Epoch {epoch} Saving Embedding...*****\")\n",
        "            self.model.save_embedding(self.id2word, os.path.join(self.output_file_name, f'w2v_{epoch}.txt'), True if 'cuda' in self.device.type else False)\n",
        "            print(f\"*****Epoch {epoch} Embedding Saved at {os.path.join(self.output_file_name, f'w2v_{epoch}.txt')}*****\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-19T14:34:29.561892Z",
          "start_time": "2022-02-19T14:34:26.103659Z"
        },
        "id": "Ywx9R8n24WSp"
      },
      "outputs": [],
      "source": [
        "output_file = os.path.join(\".\", \"word2vec_wiki\")\n",
        "# Word2Vec 클래스의 인스턴스 생성\n",
        "w2v = Word2Vec(docs, output_file, device, n_neg_sample=10, iteration=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-19T14:34:34.615469Z",
          "start_time": "2022-02-19T14:34:34.055502Z"
        },
        "id": "ufBxjKxN4WSp"
      },
      "outputs": [],
      "source": [
        "# 학습 데이터 셋 및 데이터 로더 생성 (위에서 생성한 w2v의 attribute들을 argument에 적절히 넣기)\n",
        "dataset = None\n",
        "train_dataloader = None\n",
        "len(train_dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-19T14:45:38.362817Z",
          "start_time": "2022-02-19T14:34:37.382371Z"
        },
        "id": "9JBUrUJ34WSp"
      },
      "outputs": [],
      "source": [
        "# 학습\n",
        "w2v.train(train_dataloader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3uTIm4vJ4WSp"
      },
      "source": [
        "### 유사한 단어 확인\n",
        "- 사전에 존재하는 단어들과 유사한 단어를 검색해보자. Gensim 패키지는 유사 단어 외에도 단어간의 유사도를 계산하는 여러 함수를 제공한다. 실험을 통해 word2vec의 한계점을 발견했다면 아래에 markdown으로 작성해보자. \n",
        "- [Gensim 패키지 document](https://radimrehurek.com/gensim/models/keyedvectors.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-19T14:47:59.605389Z",
          "start_time": "2022-02-19T14:47:59.368925Z"
        },
        "id": "AKpBuVlP4WSp"
      },
      "outputs": [],
      "source": [
        "import gensim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-19T14:49:06.590460Z",
          "start_time": "2022-02-19T14:49:05.174241Z"
        },
        "id": "AWTCodimsAq8"
      },
      "outputs": [],
      "source": [
        "word_vectors = gensim.models.KeyedVectors.load_word2vec_format('임베딩 파일 경로', binary=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-19T14:49:11.324372Z",
          "start_time": "2022-02-19T14:49:11.315429Z"
        },
        "id": "MLMh_evrsAq9"
      },
      "outputs": [],
      "source": [
        "word_vectors.most_similar(positive=None)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "word2vec의 한계점은?"
      ],
      "metadata": {
        "id": "X8lc8NQe4cT2"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "4팀_황찬희_Week3_1_assignment.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "torch",
      "language": "python",
      "name": "torch"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}